{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid prediction\n",
    "\n",
    "Today we are going to predict wheter a person will be admitted to the icu. \n",
    "The data that we use can be find at:\n",
    "https://www.kaggle.com/tanmoyx/covid19-patient-precondition-dataset?select=covid.csv\n",
    "\n",
    "We will perform several steps:\n",
    "1) Clean the data. As the data as a lot of NA values represented as numbers <br>\n",
    "2) Add weights columns as the data set contains a lot of people not being admitted to the icu.<br>\n",
    "3) Train a logistic regression model. <br>\n",
    "4) Extra: analyse the results: check what is most predictive for being admited to the icu.<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with creating a spark session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "### Specify clusers. The name. Get or create will make sure that we do not initialize two times the same session \n",
    "spark = SparkSession.builder.master('local[*]').appName('covid prediction').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next load the data. \n",
    "\n",
    "covid = spark.read.csv('./data/covid.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue=\"NA\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------------+----------+-------------+----------+-------+---------+---+---------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+-------------------+---------+---+\n",
      "|    id|sex|patient_type|entry_date|date_symptoms| date_died|intubed|pneumonia|age|pregnancy|diabetes|copd|asthma|inmsupr|hypertension|other_disease|cardiovascular|obesity|renal_chronic|tobacco|contact_other_covid|covid_res|icu|\n",
      "+------+---+------------+----------+-------------+----------+-------+---------+---+---------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+-------------------+---------+---+\n",
      "|16169f|  2|           1|04-05-2020|   02-05-2020|9999-99-99|     97|        2| 27|       97|       2|   2|     2|      2|           2|            2|             2|      2|            2|      2|                  2|        1| 97|\n",
      "|1009bf|  2|           1|19-03-2020|   17-03-2020|9999-99-99|     97|        2| 24|       97|       2|   2|     2|      2|           2|            2|             2|      2|            2|      2|                 99|        1| 97|\n",
      "|167386|  1|           2|06-04-2020|   01-04-2020|9999-99-99|      2|        2| 54|        2|       2|   2|     2|      2|           2|            2|             2|      1|            2|      2|                 99|        1|  2|\n",
      "|0b5948|  2|           2|17-04-2020|   10-04-2020|9999-99-99|      2|        1| 30|       97|       2|   2|     2|      2|           2|            2|             2|      2|            2|      2|                 99|        1|  2|\n",
      "|0d01b5|  1|           2|13-04-2020|   13-04-2020|22-04-2020|      2|        2| 60|        2|       1|   2|     2|      2|           1|            2|             1|      2|            2|      2|                 99|        1|  2|\n",
      "+------+---+------------+----------+-------------+----------+-------+---------+---+---------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+-------------------+---------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n",
      "566602\n",
      "StructType(List(StructField(id,StringType,true),StructField(sex,IntegerType,true),StructField(patient_type,IntegerType,true),StructField(entry_date,StringType,true),StructField(date_symptoms,StringType,true),StructField(date_died,StringType,true),StructField(intubed,IntegerType,true),StructField(pneumonia,IntegerType,true),StructField(age,IntegerType,true),StructField(pregnancy,IntegerType,true),StructField(diabetes,IntegerType,true),StructField(copd,IntegerType,true),StructField(asthma,IntegerType,true),StructField(inmsupr,IntegerType,true),StructField(hypertension,IntegerType,true),StructField(other_disease,IntegerType,true),StructField(cardiovascular,IntegerType,true),StructField(obesity,IntegerType,true),StructField(renal_chronic,IntegerType,true),StructField(tobacco,IntegerType,true),StructField(contact_other_covid,IntegerType,true),StructField(covid_res,IntegerType,true),StructField(icu,IntegerType,true)))\n"
     ]
    }
   ],
   "source": [
    "# Next check how many entries we have and check the schema\n",
    "\n",
    "print(covid.show(5))\n",
    "print(covid.count())\n",
    "print(covid.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we select all the columns that we want\n",
    "\n",
    "# Hint these are: 'sex', 'pneumonia', 'age', 'pregnancy', 'diabetes', 'copd', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular', 'obesity', 'renal_chronic', 'tobacco', 'icu'\n",
    "\n",
    "\n",
    "covid = covid.select('sex', 'pneumonia', 'age', 'pregnancy', 'diabetes', 'copd', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular', 'obesity', 'renal_chronic', 'tobacco', 'icu' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+---------+--------+----+-------+------------+-------------+--------------+-------+-------------+-------+---+\n",
      "|sex|pneumonia|age|pregnancy|diabetes|copd|inmsupr|hypertension|other_disease|cardiovascular|obesity|renal_chronic|tobacco|icu|\n",
      "+---+---------+---+---------+--------+----+-------+------------+-------------+--------------+-------+-------------+-------+---+\n",
      "|  1|        2| 54|        2|       2|   2|      2|           2|            2|             2|      1|            2|      2|  1|\n",
      "|  2|        1| 30|       97|       2|   2|      2|           2|            2|             2|      2|            2|      2|  1|\n",
      "|  1|        2| 60|        2|       1|   2|      2|           1|            2|             1|      2|            2|      2|  1|\n",
      "|  2|        1| 47|       97|       1|   2|      2|           2|            2|             2|      2|            2|      2|  0|\n",
      "|  2|        2| 63|       97|       2|   2|      2|           1|            2|             2|      2|            2|      2|  1|\n",
      "+---+---------+---+---------+--------+----+-------+------------+-------------+--------------+-------+-------------+-------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We only want the patients that we have info if they are admitted or not. Make sure that 0 = yes and 1 = no\n",
    "\n",
    "covid_interest = covid.filter((covid.icu == 1) | (covid.icu ==2)).withColumn('icu', covid.icu-1)\n",
    "covid_interest.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121788"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### How many patients are left?\n",
    "covid_interest.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09\n",
      "11.04\n"
     ]
    }
   ],
   "source": [
    "### What percentage of patient where admitted to the icu?\n",
    "# What should the weight by of the patients that were admited?\n",
    "import numpy as np\n",
    "\n",
    "icu_percentage = np.round(covid_interest.filter(covid_interest.icu == 0).count()/ covid_interest.filter(covid_interest.icu == 1).count(), 2)\n",
    "icu_weight = np.round(covid_interest.filter(covid_interest.icu == 1).count()/ covid_interest.filter(covid_interest.icu == 0).count(), 2)\n",
    "print(icu_percentage)\n",
    "print(icu_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next add a column that gives appropiate weight to the columns, this is used for weighted logistic regression. See https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.classification.LogisticRegression\n",
    "covid_interest = covid_interest.withColumn(\"weight\", when(covid_interest.icu == 0, icu_weight).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+---------+--------+----+-------+------------+-------------+--------------+-------+-------------+-------+---+------+\n",
      "|sex|pneumonia|age|pregnancy|diabetes|copd|inmsupr|hypertension|other_disease|cardiovascular|obesity|renal_chronic|tobacco|icu|weight|\n",
      "+---+---------+---+---------+--------+----+-------+------------+-------------+--------------+-------+-------------+-------+---+------+\n",
      "|  0|        1|  2|        1|       1|   1|      1|           1|            1|             1|      0|            1|      1|  1|   1.0|\n",
      "|  1|        0|  2|        2|       1|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  0|        1|  2|        1|       0|   1|      1|           0|            1|             0|      1|            1|      1|  1|   1.0|\n",
      "|  1|        0|  2|        2|       0|   1|      1|           1|            1|             1|      1|            1|      1|  0| 11.04|\n",
      "|  1|        1|  2|        2|       1|   1|      1|           0|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  0|        0|  2|        1|       1|   1|      1|           1|            1|             1|      0|            1|      1|  1|   1.0|\n",
      "|  0|        0|  2|        1|       1|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  1|        1|  2|        2|       1|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  0|        1|  2|        1|       1|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  0|        1|  2|        1|       1|   1|      1|           1|            1|             1|      0|            1|      0|  1|   1.0|\n",
      "|  0|        1|  2|        1|       0|   0|      0|           0|            1|             0|      1|            1|      1|  1|   1.0|\n",
      "|  1|        1|  2|        2|       1|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  1|        0|  2|        2|       1|   1|      1|           0|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  1|        1|  2|        2|       1|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  0|        0|  2|        1|       0|   1|      1|           1|            1|             1|      0|            1|      1|  1|   1.0|\n",
      "|  1|        1|  2|        2|       0|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  1|        0|  2|        2|       1|   0|      1|           1|            1|             1|      1|            1|      0|  1|   1.0|\n",
      "|  0|        1|  2|        1|       0|   1|      1|           1|            1|             1|      1|            1|      0|  1|   1.0|\n",
      "|  1|        1|  2|        2|       1|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "|  1|        1|  2|        2|       1|   1|      1|           1|            1|             1|      1|            1|      1|  1|   1.0|\n",
      "+---+---------+---+---------+--------+----+-------+------------+-------------+--------------+-------+-------------+-------+---+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Next we make sure that we map every entry of the columns we are interested in to (0,1,2) (yes, no, unknown/na)\n",
    "# Hint look at what values for unbknown/na is used\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "columns_to_map = [\n",
    "    'sex', 'pneumonia', 'age', 'pregnancy', 'diabetes', 'copd', 'inmsupr', 'hypertension', 'other_disease', 'cardiovascular', 'obesity', 'renal_chronic', 'tobacco' \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for column in columns_to_map:\n",
    "    \n",
    "    covid_interest = covid_interest.withColumn(column, when(covid[column] < 3, covid[column] - 1).otherwise(2) )\n",
    "    \n",
    "covid_interest.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split the data in train test, use 80% as train data. use 17 as your seed\n",
    "covid_train, covid_test = covid_interest.randomSplit([0.8, 0.2], 17) ## 17 = seed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Next create the pipeline that does these steps: stringindexer, onehotencoder, vectorassembler and lastly logisticregression\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "\n",
    "index_cols = [\"index_\" + col for col in columns_to_map]\n",
    "one_hot_cols = ['one_hot_' + col for col in columns_to_map]\n",
    "\n",
    "indexer = StringIndexer(inputCols=columns_to_map, outputCols=index_cols)\n",
    "one_hot = OneHotEncoder(inputCols=index_cols, outputCols=one_hot_cols)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=one_hot_cols, outputCol=\"features\")\n",
    "logic_regress = LogisticRegression(labelCol=\"icu\", weightCol=\"weight\")\n",
    "\n",
    "\n",
    "pipeline_regression = Pipeline(stages=[indexer, one_hot, assembler, logic_regress])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit the pipeline\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "pipeline_regression = pipeline_regression.fit(covid_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|prediction|icu|\n",
      "+----------+---+\n",
      "|       0.0|  1|\n",
      "|       0.0|  1|\n",
      "|       0.0|  1|\n",
      "|       0.0|  1|\n",
      "|       0.0|  0|\n",
      "+----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the testing data and show the first 5\n",
    "predictions = pipeline_regression.transform(covid_test)\n",
    "predictions.select('prediction', 'icu').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6713172251477334"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate with the binaryClassification evaluator, use weight as the cols. \n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "BinaryClassificationEvaluator(labelCol='icu', weightCol=\"weight\").evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is an open part:\n",
    "Several things that you can do:\n",
    "1) Improve upon the model by using grid search <br>\n",
    "2) Use another model e.g: SVC <br>\n",
    "3) Explore which parameters are usefull, by checking the weights of each feature. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
