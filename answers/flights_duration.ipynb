{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting flight duration\n",
    "\n",
    "This time we will build a model that predicts the duration of the flight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "### Specify clusers. The name. Get or create will make sure that we do not initialize two times the same session \n",
    "spark = SparkSession.builder.master('local[*]').appName('flights_regression').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the data\n",
    "flights = spark.read.csv('../data/flights.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True, ### slow -> must go true the entire data once. We can specify the schema.\n",
    "                         nullValue=\"NA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351| null|\n",
      "|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n",
      "|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n",
      "|  9| 13|  1|     AA|   419|ORD|1236| 10.33|     195|   -5|\n",
      "|  4|  2|  5|     AA|   325|ORD| 258|  8.92|      65| null|\n",
      "|  5|  2|  1|     UA|   704|SFO| 550|  7.98|     102|    2|\n",
      "|  7|  2|  6|     AA|   380|ORD| 733| 10.83|     135|   54|\n",
      "|  1| 16|  6|     UA|  1477|ORD|1440|   8.0|     232|   -7|\n",
      "|  1| 22|  5|     UA|   620|SJC|1829|  7.98|     250|  -13|\n",
      "| 11|  8|  1|     OO|  5590|SFO| 158|  7.77|      60|   88|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### show the first 10 entries\n",
    "flights.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mon', 'int'),\n",
       " ('dom', 'int'),\n",
       " ('dow', 'int'),\n",
       " ('carrier', 'string'),\n",
       " ('flight', 'int'),\n",
       " ('org', 'string'),\n",
       " ('mile', 'int'),\n",
       " ('depart', 'double'),\n",
       " ('duration', 'int'),\n",
       " ('delay', 'int')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check the datatype\n",
    "flights.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the na columns\n",
    "flights_na_cleaned = flights.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove columns without any information\n",
    "flights_cleaned = flights_na_cleaned.drop(\"flight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|\n",
      "+---+---+---+-------+---+------+--------+-----+------+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create a km column\n",
    "\n",
    "from pyspark.sql.functions import round\n",
    "### Now we show how to create new columns\n",
    "# We do not like the imperial system hence we will create a km column and remove the mile column\n",
    "flights_km = flights_cleaned.withColumn(\"km\", round(flights.mile *1.60934, 0 )).drop('mile')\n",
    "\n",
    "flights_km.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+-------------+---------------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|  org_one_hot|carrier_one_hot|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+-------------+---------------+\n",
      "|  0| 22|  2|     UA|ORD| 16.33|      82|   30| 509.0|    1|        0.0|    0.0|(7,[0],[1.0])|  (8,[0],[1.0])|\n",
      "|  2| 20|  4|     UA|SFO|  6.17|      82|   -8| 542.0|    0|        0.0|    1.0|(7,[1],[1.0])|  (8,[0],[1.0])|\n",
      "|  9| 13|  1|     AA|ORD| 10.33|     195|   -5|1989.0|    0|        1.0|    0.0|(7,[0],[1.0])|  (8,[1],[1.0])|\n",
      "|  5|  2|  1|     UA|SFO|  7.98|     102|    2| 885.0|    0|        0.0|    1.0|(7,[1],[1.0])|  (8,[0],[1.0])|\n",
      "|  7|  2|  6|     AA|ORD| 10.83|     135|   54|1180.0|    1|        1.0|    0.0|(7,[0],[1.0])|  (8,[1],[1.0])|\n",
      "|  1| 16|  6|     UA|ORD|   8.0|     232|   -7|2317.0|    0|        0.0|    0.0|(7,[0],[1.0])|  (8,[0],[1.0])|\n",
      "|  1| 22|  5|     UA|SJC|  7.98|     250|  -13|2943.0|    0|        0.0|    5.0|(7,[5],[1.0])|  (8,[0],[1.0])|\n",
      "| 11|  8|  1|     OO|SFO|  7.77|      60|   88| 254.0|    1|        2.0|    1.0|(7,[1],[1.0])|  (8,[2],[1.0])|\n",
      "|  4| 26|  1|     AA|SFO| 13.25|     210|  -10|2356.0|    0|        1.0|    1.0|(7,[1],[1.0])|  (8,[1],[1.0])|\n",
      "|  4| 25|  0|     AA|ORD| 13.75|     160|   31|1574.0|    1|        1.0|    0.0|(7,[0],[1.0])|  (8,[1],[1.0])|\n",
      "|  8| 30|  2|     UA|ORD| 13.28|     151|   16|1157.0|    1|        0.0|    0.0|(7,[0],[1.0])|  (8,[0],[1.0])|\n",
      "|  3| 16|  3|     UA|ORD|   9.0|     264|    3|2808.0|    0|        0.0|    0.0|(7,[0],[1.0])|  (8,[0],[1.0])|\n",
      "|  0|  3|  4|     AA|LGA| 17.08|     190|   32|1765.0|    1|        1.0|    3.0|(7,[3],[1.0])|  (8,[1],[1.0])|\n",
      "|  5|  9|  1|     UA|SFO|  12.7|     158|   20|1556.0|    1|        0.0|    1.0|(7,[1],[1.0])|  (8,[0],[1.0])|\n",
      "|  3| 10|  4|     B6|ORD| 17.58|     265|  155|2792.0|    1|        4.0|    0.0|(7,[0],[1.0])|  (8,[4],[1.0])|\n",
      "| 11| 15|  1|     AA|ORD|  6.75|     160|   23|1291.0|    1|        1.0|    0.0|(7,[0],[1.0])|  (8,[1],[1.0])|\n",
      "|  8| 18|  4|     UA|SJC|  6.33|     160|   17|1526.0|    1|        0.0|    5.0|(7,[5],[1.0])|  (8,[0],[1.0])|\n",
      "|  2| 14|  5|     B6|JFK|  6.17|     166|    0|1519.0|    0|        4.0|    2.0|(7,[2],[1.0])|  (8,[4],[1.0])|\n",
      "|  7| 21|  4|     OO|ORD|  19.0|     110|   21| 977.0|    1|        2.0|    0.0|(7,[0],[1.0])|  (8,[2],[1.0])|\n",
      "| 11|  6|  6|     OO|SFO|  8.75|      82|   40| 509.0|    1|        2.0|    1.0|(7,[1],[1.0])|  (8,[2],[1.0])|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create the index and onehot encoding for carrier and org\n",
    "\n",
    "### Creating an indexer ( not a one hot encoding)\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# Creating the object, describing the input collumn and the output column\n",
    "indexer = StringIndexer(inputCol=\"carrier\", outputCol='carrier_idx')\n",
    "\n",
    "# The indecer needs to be fit on the data\n",
    "indexer_model = indexer.fit(flights_delayed)\n",
    "\n",
    "# Then we need to transform the data. \n",
    "flights_indexed = indexer_model.transform(flights_delayed)\n",
    "\n",
    "# A one liner for the org column\n",
    "flights_indexed = StringIndexer(inputCol=\"org\", outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)\n",
    "\n",
    "\n",
    "\n",
    "# Create an instance of the one hot encoder\n",
    "onehot_org = OneHotEncoder(inputCols=['org_idx'], outputCols=['org_one_hot'])\n",
    "\n",
    "# Apply the one hot encoder to the flights data\n",
    "onehot_org = onehot_org.fit(flights_indexed)\n",
    "flights_onehot = onehot_org.transform(flights_indexed)\n",
    "\n",
    "\n",
    "\n",
    "onehot_carrier = OneHotEncoder(inputCols=['carrier_idx'], outputCols=['carrier_one_hot'])\n",
    "\n",
    "# Apply the one hot encoder to the flights data\n",
    "onehot_carrier = onehot_carrier.fit(flights_onehot)\n",
    "flights_onehot = onehot_carrier.transform(flights_onehot)\n",
    "\n",
    "# Check the results\n",
    "flights_onehot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------+--------+\n",
      "|features                                                   |duration|\n",
      "+-----------------------------------------------------------+--------+\n",
      "|(20,[1,2,3,11,18,19],[22.0,2.0,1.0,1.0,509.0,16.33])       |82      |\n",
      "|(20,[0,1,2,3,12,18,19],[2.0,20.0,4.0,1.0,1.0,542.0,6.17])  |82      |\n",
      "|(20,[0,1,2,4,11,18,19],[9.0,13.0,1.0,1.0,1.0,1989.0,10.33])|195     |\n",
      "|(20,[0,1,2,3,12,18,19],[5.0,2.0,1.0,1.0,1.0,885.0,7.98])   |102     |\n",
      "|(20,[0,1,2,4,11,18,19],[7.0,2.0,6.0,1.0,1.0,1180.0,10.83]) |135     |\n",
      "+-----------------------------------------------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create a feature column\n",
    "\n",
    "# Import the necessary class\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Create an assembler object with mon, dom, dow, carrier_one_hot, org_one_hot, km and depart as inputcols.\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'mon', 'dom', 'dow', 'carrier_one_hot', 'org_one_hot', 'km', 'depart'\n",
    "], outputCol='features')\n",
    "\n",
    "# Consolidate predictor columns\n",
    "flights_assembled = assembler.transform(flights_onehot)\n",
    "\n",
    "# Check the resulting column\n",
    "flights_assembled.select('features', 'duration').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25475650433622415\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## First create a random split\n",
    "# Split into training and testing sets in a 80:20 ratio\n",
    "\n",
    "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], 17) ## 17 = seed\n",
    "\n",
    "# Check that training set has around 80% of records\n",
    "training_ratio = flights_test.count() / flights_train.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|km    |duration|\n",
      "+------+--------+\n",
      "|2570.0|230     |\n",
      "|1180.0|170     |\n",
      "|1180.0|120     |\n",
      "|1180.0|135     |\n",
      "|415.0 |70      |\n",
      "|378.0 |80      |\n",
      "|2375.0|200     |\n",
      "|2303.0|200     |\n",
      "|4089.0|315     |\n",
      "|3869.0|301     |\n",
      "+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create a linear regression model\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Create a classifier object and fit to the training data\n",
    "regression = LinearRegression(labelCol=\"duration\")\n",
    "regression_model = regression.fit(flights_train)\n",
    "\n",
    "# Create predictions for the testing data and take a look at the predictions\n",
    "prediction = regression_model.transform(flights_test)\n",
    "prediction.select(\"km\", \"duration\").show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.62615179127788"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the regression evaluator\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "RegressionEvaluator(labelCol='duration').evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0993, 0.0116, -0.0438, -12.0206, -14.3051, -10.3386, -13.2302, -19.8815, -10.1271, -15.9004, -3.5484, 35.7037, 27.0391, 63.0785, 54.9218, 23.4041, 26.3584, 25.7249, 0.0749, 0.1572])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look at the coefficients\n",
    "regression_model.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test RMSE is 11.284722155554833\n",
      "[0.0,0.0,0.0,0.0,0.0,0.0,-2.0472808295171787,0.0,3.163688572941937,0.0,-9.253784860109985,4.9474726870223,0.0,27.56984696278987,20.449991866089523,-1.6917998904467837,0.0,0.0,0.07347562336280287,0.0]\n",
      "Number of coefficients equal to 0: 12\n"
     ]
    }
   ],
   "source": [
    "# Fit a LinearRegression model with regParam=1 and elesticNatParam=1\n",
    "regression = LinearRegression(labelCol='duration', regParam=1, elasticNetParam=1).fit(flights_train)\n",
    "\n",
    "# Calculate the RMSE on testing data\n",
    "rmse = RegressionEvaluator(labelCol='duration').evaluate(regression.transform(flights_test))\n",
    "print(\"The test RMSE is\", rmse)\n",
    "\n",
    "# Look at the model coefficients\n",
    "coeffs = regression.coefficients\n",
    "print(coeffs)\n",
    "\n",
    "# Number of zero coefficients\n",
    "zero_coeff = sum([beta == 0 for beta in regression.coefficients])\n",
    "print(\"Number of coefficients equal to 0:\", zero_coeff)\n",
    "\n",
    "# Question: what is the difference?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
